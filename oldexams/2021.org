* 1
Other computer

* 2
** 2.1
I would measure the average latency pr. successful query. This helps
us understand how long a query typically takes
We can also measure the total throughput of queries - that is how many
queries can we handle per second. This gives a grasp to how many
queries the two systems can handle

remember: throughput=1/latency

Ratio of aborted transactions since this tells us how effective
optimistic concurrency control is versus how many deadlock locking
based approach experiences.

** 2.2
Workloads
For workload i would use an ensemble of queries that i know were run
against another in-memory database - realistic workload.

Parameters
Parameters for the workload is the
top-k used queries.
Length of queries
Num tables used
Read/write ratio

Measurements
I would use interval timer to measure latency of
each query. For throughput i would use event-count where an event is a
commit.

It was not in-memory i would check event-count for page swaps
and IO calls.

* 3
** 3.1
*** 3.1
T1 R(X)    R(Y)       W(Y) C
T2                                          R(Y) W(Y) W(Z) C
T3              W(Z)          R(X)  W(X) C

This is not serial since the actions of the transactions are
interleaved. It is serializable since the outcome is as if T2, T1 and
then T3 had run
(conflicts are: T1->T3, T3 -> T2, T2 -> T1, T1 -> T2 

*** 3.2
T1             R(X)              R(Y)       W(Y)      C
T2                          R(Y)        W(Y)     W(Z)   C
T3 W(Z)  R(X)        W(X) C
We have a cycle in the serializability graph with  T1->T2, T2->T1, and
therefore there can be no equivalent serial schedule

*** 3.3
T1                R(X) R(Y) W(Y)  C
T2  R(Y)    W(Y)                    W(Z) C
T3                                          W(Z) R(X) W(X)

T1 gets exclusive lock while T2 has shared lock so not
possible. Conflicts are: T2 -> T1, T1 -> T3, T2 -> T3, no cycle so it
is conflict serializable.

*** 3.4
T1                              R(X)                   R(Y)    W(Y) C
T2         R(Y)                        W(Y)    W(Z) C
T3    W(Z)       R(X)  W(X)  C
or a serial schedule

Conflicts: T3->T2, T2->T1

*** 3.5
1. Yes
2. No, since T2 acquires write lock on y while T1 has shared lock and holds
   it since it needs a later upgrade
3. Yes
4. yes

** 3.2
Ta   R(X) W(X)
Tb              R(X)
Tc                    R(X)
If Ta decides to abort, then since Tb and Tc have a dirty read, they
need to abort as well. Furthermore it is allowed by C2PL since Ta
drops lock on X after the write

** 3.3
*** 3.3.1
Yes Tb will wait for the lock on X hold by Ta. At the same time Ta
waits for lock on y hold by Tb.

*** 3.3.2
Yes, Ta needs to acquire exclusive lock on Y before it can start
dropping locks, but Tb needs lock exclusive lock on X before it can
start dropping shared lock on Y.

* 4
** 4.1
LSN  PREV_LSN    XACT_ID    TYPE    PAGE_ID     UNDONEXTLSN
------------------------------------------------------------
1                          begin c
2                          end c
3     0           T3       Update   P42           0
4     0           T2       Update   P42           -
5     0           T1*      Update   P66           -
6     4           T2       Commit   P42           -
7     3           T3       Commit   -P66           -
8     5           T1       Update   P65           -
9     6           T2       end      -             -
10    8           T1       Update   P65           -
###CRASH###
(there cannot be an end record for T3 since otherwise it would be
removed from Xact table)

** 4.2
1. Winner={T2, T3} since they commit, loser={T1} since this does not
   commit and is active
2. Redo-start=recLSN 3, since this is the smallest recLSN in the dirty
   page table
   Undo-start=10, since this is the largest lsn of the loser
   transaction
   Undo-end-5 since this is the oldest action of T1
3. LSN 3, 4, 5,8,10 since these are updates on a dirty page
4. LSN 10, 8, 5 since the only loser is T1 and this is its updates
5. 
LSN  PREV_LSN    XACT_ID    TYPE    PAGE_ID     UNDONEXTLSN
------------------------------------------------------------
1                          begin c
2                          end c
3     0           T3       Update   P42           0
4     0           T2       Update   P42           -
5     0           T1*      Update   P66           -
6     4           T2       Commit   P42           -
7     3           T3       Commit   -P66           -
8     5           T1       Update   P65           -
9     6           T2       end      -             -
10    8           T1       Update   P65           -
###CRASH###
11                T3       END      -             -
12                T1       Abort    P65           -
13   -            T1       CLR      p65           8  
14                T1       CLR      p65           3
15                T1       CLR      p65           0
16                T1       END

* 5
** 5.1
1. 
    Bob     - e1(1), e12(9)
    FacePub - e2(2), e3(3), e5(4), e7(6), e8(7), e11(8)
    Alic    - e10(9), e9(8),
    Emily   - e4(4), e6(5)
2. 
    Bob     - (0,0,0,0), e1(1,0,0,0), (2,6,0,2)
    FacePub - (0,0,0,0), e2(1,1,0,0), e3(1,2,0,0), e5(1,3,0,0),
    e7(1,4,0,2), e8(1,5,0,2), e11(1,6,0,2)
    Alice   - (0,0,0,0), e9(1,5,1,2), e10(1,5,2,2)
    Emily   - (0,0,0,0), e4(1,2,0,1), e6(1,2,0,2)
3.
   Lamport: The original message m1'' sent to Alice carries timestamp
   e5(4), and the reply from Emily carries timestamp e8(7), so the
   timestamps of the two messages say timestamp(e5) < timesamp(e8),
   however, this does not for lamport clock tell the ordering that e5
   preceedes e8, so Alice cannot tell.
   For vector timestamps, we have e5 and e8 are attatched to messages
   m1'' and m2' respectively. We can see that e5[i] <= e8[1] and e5 !=
   e8 which does mean for vector clock that e5 preceedes e8 and
   therefore Alice can tell the ordering of messages.

** 5.2
1. Based on the architechture of the figure, with a primary
   dispatcher, we need synchronoys primary-site replication. This is
   to ensure data is not lost.
   P2P could also be a good, and then it is assumed that conflicts in
   groups are rare.
2. For primary site, with synchronous replication it depends. If we
   assume most operations are READ, then this is good since any
   replica can handle this. If we have most WRITE operations, the
   dispatcher can dossed by the clients.
   For peer to peer, one peer going down will not break the system.

** 5.3
1. First, bob send the message to the service. FacePub then starts the
   prepare phase by asking the two nodes (Alice, Emily) to run the
   transaction (log prepare).
   If they both respond yes, log COMMIT, and send COMMIT to Alice and
   Emily processes. If one replies NO send Abort. If Ack is received
   by both, then log end 
   Type, Content
   Prepare, msg to Emily
   Prepare, msg to Alice
   Response, Commit/Abort Emily
   Response, Commit/Abort Alice
   Ack, Receive Emily
   Ack, Received Alice
   end
2. The centralized deadlock prevention mechanism causes Emily to abort
   the transaction after having received m1 and starts to
   prepare. Therefore, assuming Emily still has the prepare msg, Emily
   sends NO to the transaction coordinator.
   (FacePub) and FacePub replies Abort to both Emily and Alice and
   they then ACK.
   Coordinator might also abort Emily after receiving msg.
   We might however have the case that after abort, Emily loses the
   msg. A respond is only send if coordinator resend prepare.


* 6
** 6.1
1. Natural join: 
