1. RPC
	- At most once
		Subscribing to a channel. We want the user to subscribe to a channel
		at most once, throwing an error if it fails. It is imagined that the service
		costs money, so repeated subscriptions would be bad.
	- Exactly once
		Creating an account. We want only the account to be created once,
		and throwing an error or duplicated accounts is undesirable
	- At least once
		Liking the video. In this case the most important part is that the
		video receives the like for the video, but if the request fails, then
		we can just retry not caring if the video gets liked too many times.

2. Performance
2.1 Metrics
	- It will be interesting to measure the throughput of transaction through the database.
	This can be #transaction/#minute
	This is especially interesting when measuring the two different concurrency control
	mechanism
	- Number of aborts can also be interesting to see comparing the two CC meachanisms
	- Latency of the transactions is less interesting
2.2 Experiments
Describe the experiments you would setup:
How would you define/select the workloads for the ex- periments?
	- Workload will be in terms of number of clients, N, doing queries
	against the database
	- Difficulty of the queries - this in terms of number of relations
	they consider an the number af relational operations.
	Here it is imagined that there are preconfigured increasingly
	difficult settings of the two paremeters
	- We would need a synthetic database so we can test these parameters.
	We can abstract operations away to READ/WRITE
	and the configure in terms of READ/WRITE ratio

	- Ideally we want to replicate a database that is similar to what MeagreSQL
	will be used for, and then use the N clients and different difficulties
	of the preconfigured queries

What are the parameters of the workloads?
	- See above
How would you measure the above metrics?
	- We would use timers for measuring the throughput.
	The timers could potentially be at the clients, so there is no overhead
	of the service, and then we aggregate the results after the experiments.
Would your setup differ if MeagreSQL was not an in-memory database?
	- If it was not in memory resident database, then we should also measure
	number of page-swaps or I/O interactions.
	Meaning different experiments and metrics would have to be conducted

3.
3.1
3.1.1
T1: R(X)                            R(Y) W(Y) C
T2:         R(Y) W(Y) W(Z) C
T3:                                                      W(Z) R(X) W(X) C
The schedule is equivalent to the serial schedule T2, T1, T3

3.1.2
T1: R(X) R(Y)          W(Y) C
T2: 	             R(Y)             W(Y) W(Z) C
T3: 		                                          W(Z) R(X) W(X) C
We have the precedence graph
T1 -> T2, T2 -> T1 which makes a cycle, so it is not conflict serializable

3.1.3
T1:  R(X)                           R(Y) W(Y) C
T2:  					                  R(Y) W(Y) W(Z) C
T3:         W(Z) R(X) W(X) C
This is conflict equivalent to running T1, T2, T3
Conflicts: T1->T3, T1 -> T2, T3 -> T2
Cannot be generated by S2PL, since T1 has a shared lock on X for its R(X) action
meanwhile T3 gets an exclusive lock on X for its W(X) action.

3.1.4
T1: R(X) R(Y) W(Y) C
T2: 				R(Y) W(Y) W(Z) C
T3: 							 W(Z) R(X) W(X) C
A serial schedule can be generated by both

3.1.5
	1. Yes, since except for the first R(X) in T1 everything runs serially
	2. No, 2PL makes CS schedules, and T2 has a shared lock on Y while
	T1 tries to acquire exclusive lock on Y for its W(Y) action
	3. Yes, only issue would be whether T3 can acquire exclusive lock for its W(X),
	but T1 has dropped shared lock after it has performed R(X)
	4. Yes, a completely serial schedule can be generated by 2PL


1 Hour

3.2 Cascading aborts
Give a transaction schedule of three (uncommitted) transactions Ta, Tb, and Tc
that could have been generated by conservative two-phase locking (C2PL)
with lock downgrades (from exclusive to shared) and in which the abort
of one transaction will cause the abort of the other two transactions.
Explain your solution, in particular justifying why the caused aborts must happen.
Note: Unlike in the previous exercise, you may choose which actions comprise Ta, Tb, and Tc.

Ta: W(X)                                    R(Z)           R(Y)
Tb:           R(X)         W(Z)                                    R(Y)
Tc:                   R(X)           R(Z)          W(Y)
If Ta aborts, then Tb,Tc have a dirty read on X
If Tb aborts, then Ta, Tc habe a dirty read on Z
If Tc aborts, then Ta, Tb have a dirty read on Y

3.3 Deadlocks
Ta: R(X)        W(X) 		W(Y) C
Tb:       R(Y)		W(X)			W(Z) C
3.3.1
	Yes, because Tb will holds it shared lock on Y,
	and its waiting to acquire exclusive lock on X
	Ta is holding the exclusive lock on X, but waiting for the exclusive lock on Y
	before it can drop its exclusive lock on X.

	Waits-for graph is: Ta->Tb, Tb->Ta, so there is a cycle

3.3.2
	No because now Ta has released its lock on X after its W(X) action.
	Therefore, Tb can now do its W(X) without waiting.
	Additionally Tb drops its shared lock on Y immediately after R(Y)
	and Ta will not wait to acquire the exclusive lock on Y.

15 min

4.
	XACT_ID	status	lastlstn
	------------------------
	T1		Running	10
	T3		Commit	7

	PID		recLSn
	---------------
	P42		3
	P65		8
	P220		5

4.1

	LSN	PREV_LSN	XACT_ID	TYPE 		PAGE_ID 	UNDONEXTLSN
	---------------------------------------------------------
	1.					B_CKPT
	2.					E_CKPT
	3.	-		T1		Update		P42		-
	4.	-		T2		Update		P42		-
	5.	-		T3		Update		P220		-
	6.	4		T2		Commit		-		-
	7. 	5		T3		Commit		-
	8.	3		T1		Update		P65		-
	9.	6		T2		END
	10.	8		T1		Update		P65
			############Crash############
4.2

	1. the sets of winner and loser transactions;
		Winners = {T3, T2}
		Losers = {T2}
	2. the values for the LSNs where the redo phase starts and where the undo phase ends;
		Redo start - recLSN
		Undo-end - LSN 3
	3. the set of log records that may cause pages to be rewritten during the redo phase;
		{3, 4, 5, 8, 10}
	4. the set of log records undone during the undo phase;
		{10, 8, 3}
	5. the contents of the log after the recovery procedure completes.
	LSN	PREV_LSN	XACT_ID	TYPE 		PAGE_ID 	UNDONEXTLSN
	---------------------------------------------------------
	1.					B_CKPT
	2.					E_CKPT
	3.	-		T1		Update		P42		-
	4.	-		T2		Update		P42		-
	5.	-		T3		Update		P220		-
	6.	4		T2		Commit		-		-
	7. 	5		T3		Commit		-
	8.	3		T1		Update		P65		-
	9.	6		T2		END
	10.	8		T1		Update		P65
			############Crash############
	11	7		T3		END			-
	12	10		T1		Abort		-
	13	12		T1		CLR 10		P42		8
	14	13		T1		CLR 8		P42		3
	15	14		T1		CLR 3		P42		-
	16	15		T1		END

20 min

5.
5.1 Lamport and Vector Clocks
5.1.1
P1: 0	e1(1)												e12(9)
P2: 0		e2(2)	e3(3)	e5(4)		e7(6)	e8(7)			e11(8)
P3: 0									e9(8)	e10(9)
P4: 0				e4(4)		e6(5)

5.1.2

P1: e1(1,0,0,0)														e12(2,6,0,2)
P2: e2(1,1,0,0)	e3(1,2,0,0)		e5(1,3,0,0)		e7(1,4,0,2)	e8(1,5,0,2) e11(1,6,0,2)
P3:	 													e9(1,5,1,2) e10(1,5,2,2)
P4:					e4(1,2,0,1)		e6(1,2,0,2)

5.1.3
	- Lamprt logical clocks
		No
		This logical clock does not have the property that
		timestamp(e5) < timestamp imples e5 -> e6 (e5 preceedes e6)
		thefore Alice will not be able to tell the ordering of the messages
		and therefore not know that m1 comes before m2
	- Vector clocks
		Yes
		This clock does have the property
		timestamp(e5) < timestamp imples e5 -> e6 (e5 preceedes e6)
		So Alice can see by the timestamp attached to the msg that the
		message from Bob preceedes the one from Emily.
17 min

5.2 Scalability and Reliability
5.2.1
	- Asynchronous peer to peer would be a natural fit
	Group members each have the master record, or part of it.
	Sending a message in a group then allows the peers to propagate the update.
	Makes sense since the operations are associative but not commutative.

5.2.2
	Since there are multiple copies of the master record, it is very unlikely
	that each peer with a copy is down. This make it an efficient approach
	to replication in terms of reliability

	Synchronous replication would be better, since we have no issues with
	conflicts that in worst case lead to message loss
	Reads from a replica is also efficient. This is good since it
	is imagined most traffic will be reading messages.

15 min
5.3 2PC
5.3.1
	- Coordinator logs (prepare, Xact-ID, P3, P4) and sends prepare to P3 and P4
	- Depending on the response the coordinator writes a log with
		(commit/abort, Xacit-ID, P3, P4) which forces the log to stable storage.
		Sends the decision to P3 and P4
	- Writes (done, Xact-ID, P3, P4) after rceiving all ack

5.3.2
	Emily (P4) receives m'1, and crashes before sending yes/no to the coordinator.

	In this case, the coordinator will just wait for the response from P4.
	Two cases now arise
		- Coordinator aborts
		- Coordinator waits
	Assuming Coordinator wais
	When P4 is restarted it will see that it has a prepare log record written,
	and P4 contact the coordinator for the status - in case it was aborted.
	The coordinator will now tell P4 a transaction is ongoing and P4 can
	commit or abort.

	If the coordinator aborts
	When P4 is restarted and contacts the coordinator, the coordinator just
	sends abort.
12 min

6.
6.1
The first task is to select all the records in Customers,
where age is greater than 50 and city is equal to “Copenhagen”.

6.1.1: Suppose there is a clustered B+ tree index on Custerms.age,
and a non-clustered B+ tree index on Customers.city. Both indices are indirect indices,
i.e. the data entries in the leaf nodes of the B+ Trees contain pointers to the actual data
records. There are 150, 000 records having age > 50, 100, 000 records having
city = "Copenhagen", and 60, 000 records meeting both conditions.

Suppose each page can contain 100 records, and both indices are already
fully loaded into the main memory. What are the possible approaches to
answer the selection query?
What is the worst-case I/O cost of using each of these approaches?
Briefly explain your answer?

	- Sequential scan
	Scans through the entire customer table with 5,000 pages and thus
	also 5,000 I/O

	-We can use the index on Customers.age to get a superset of records.
	We just scan through the index, until we find the first matching record.
	Then since the index is clustered on age, we can quickly scan through
	all matching records on age and on the fly select those with city="Copenhagen".
	Since we have 150,000 we use 150,000/100 = 1,500 pages and 1,500 I/O since
	we had an index on Customers.age

	- Using both indicies
	First we check if the data entry of age is contained in the data entry of city
	If not discard it.
	This means we have to lookup the age first, so we end up with
	1,500 I/O


	- Alternatively, we use index on Customers.Age to get the first 150,000 records.
	This takes 1,500 I/O.
	Then we use index on Customers.city to get the remaining 100,000 records.
	Since this is a non-clustered index we can worst case spend 100,000 I/O.
	Then we do the intersection on the two
	Very slow due to using non-clustered index on Customers.city

6.2
Another task of the data analyst is to produce sales statistics:
“for each customer, return the total number of tickets purchased by them”.
The schema of the results should be (cID, name, age, city, nTickets).
Suppose the database server used by the data analyst has 200 buffer pages.
Answer the following questions.

6.2.1
The first step is joining the tables Tickets and Customers on cID.
Consider Grace Hash Join and Sort Merge Join.
Which one of them is the most efficient to perform this step?
Briefly explain your answer.